---
layout: post
title: "AI 글쓰기, 초안보다 ‘비평 루프’가 더 중요하다"
date: 2026-02-01 00:00:00 +0900
description: "생성→비평→수정 루프가 왜 AI 글 품질을 끌어올리는지, 간단한 PoC와 함께 정리했다."
categories: [배운 것]
tags: [ai, writing, critique, loop, workflow]
---

나는 AI 글쓰기에서 **초안보다 ‘비평 루프’가 더 중요하다**고 믿는다. 모델이 똑똑해질수록 “첫 문장부터 완벽할 거야”라는 기대가 커지지만, 현실은 반대다. **좋은 글은 대부분 두 번째, 세 번째 라운드에서 나온다.**

## TL;DR

- 생성→비평→수정 루프는 글의 **모호함, 근거 부족, 톤 단조**를 빠르게 줄인다. [Self-Refine](https://arxiv.org/abs/2303.17651)
- 비평 기준을 명확히 하면 사람 피드백 없이도 품질이 상승한다. [Constitutional AI](https://arxiv.org/abs/2212.08073)
- 실패 기록을 남기면 다음 글의 품질도 같이 오른다. [Reflexion](https://arxiv.org/abs/2303.11366)

## 배경/맥락

AI가 글을 써주는 시대에 “좋은 글”은 더 희귀해졌다. 이유는 단순하다. **생성은 쉬워졌는데, 검수는 더 어려워졌기 때문**이다. 초안을 그대로 쓰면 밋밋하고, 반복적이고, 주장에 근거가 없다. 사람 편집자는 이 문제를 직감적으로 해결하지만, 에이전트나 자동화 파이프라인에선 그 직감을 **규칙으로 번역**해야 한다.

내가 요즘 가장 신뢰하는 패턴은 “비평 루프”다. 단순히 “다시 써”가 아니라, **문제 진단 → 수정 → 재검수**가 들어가는 구조다.

## 본문(근거/논리/단계)

### 1) 비평 루프는 ‘결함의 종류’를 줄인다

Self-Refine는 생성 결과를 다시 비평하게 만들고, 그 피드백으로 재작성하는 간단한 구조를 제안한다. 핵심은 “좋고 나쁨” 같은 감정 평가가 아니라 **구체적인 결함 타입**을 잡아내는 데 있다. 예: 모호함, 근거 부족, 주장-사례 불일치. [Self-Refine](https://arxiv.org/abs/2303.17651)

이건 글쓰기에서 특히 강력하다. 글의 품질은 주로 **어떤 결함을 얼마나 빨리 잡아내느냐**로 결정된다.

### 2) 기준이 명확하면 비평은 자동화가 가능하다

Constitutional AI는 ‘헌법(원칙)’을 정해 두고 그 원칙에 맞게 비평/수정을 반복한다. 사람이 매번 피드백을 주지 않아도 되는 이유는 **기준이 선명하기 때문**이다. [Constitutional AI](https://arxiv.org/abs/2212.08073)

글쓰기에서 이건 다음과 같이 바꿔 말할 수 있다.

- “모호한 주장 금지”
- “근거 없는 결론 금지”
- “한 문단에 한 주장”

원칙이 있으면 비평은 **일관적**이 된다. 일관성은 품질을 만든다.

### 3) 비평 기록은 다음 글의 스프린트가 된다

Reflexion은 실패를 기록하고, 다음 시도에 반영하는 구조다. 글쓰기에서 이건 **편집 로그**다. 어떤 초안이 왜 망했는지 남기면, 다음 글에서 같은 실수를 반복하지 않는다. [Reflexion](https://arxiv.org/abs/2303.11366)

나는 최근 글들의 비평 로그를 따로 모아두고 있다. “근거 부족”이 계속 뜨면, 다음 초안에서 **근거를 먼저 배치**한다. 이렇게 하면 품질이 한 번에 올라간다.

### 4) 아주 작은 PoC로도 효과를 확인할 수 있다

간단한 파이썬 스크립트로도 “비평 → 수정”의 반복이 효과가 있음을 볼 수 있다. 아래는 단순 규칙 기반 예시다.

```python
from dataclasses import dataclass

text = "AI로 글을 쓰면 됩니다. 그런데 어딘가 밋밋합니다. 그래서 고쳐야 합니다."

@dataclass
class Critique:
    issue: str
    fix: str


def critique(t: str):
    issues = []
    if "됩니다" in t:
        issues.append(Critique("단정적 종결 반복", "문장 톤을 다양화"))
    if "어딘가" in t:
        issues.append(Critique("모호한 표현", "구체적 원인 제시"))
    if len(t.split()) < 15:
        issues.append(Critique("근거 부족", "작은 근거 1개 추가"))
    return issues


def revise(t: str, issues):
    for c in issues:
        if c.issue == "단정적 종결 반복":
            t = t.replace("됩니다", "되는 건 맞지만")
        if c.issue == "모호한 표현":
            t = t.replace("어딘가", "톤이 밋밋하고 관점이 없는")
        if c.issue == "근거 부족":
            t += " 예를 들어, 독자는 '그래서 뭐가 다른데?'를 바로 묻습니다."
    return t
```

이 정도만 해도 초안의 **단조로운 톤과 모호함**이 줄어든다. 중요한 건 “정답을 맞추는 것”이 아니라, **결함을 줄이는 반복**이다.

## 실수/교훈/개선점

예전엔 “모델 성능이 좋아지면 검수는 줄어들 것”이라고 생각했다. 완전히 틀렸다. 모델이 좋아질수록 **검수 기준이 더 필요**해진다. 기준이 없으면 글이 잘 써진 것처럼 보여도, 실제로는 **똑같은 결함이 반복**된다.

## 체크리스트

- 초안은 **한 번에 끝내지 않는다**
- 비평 기준을 3~5개로 먼저 정의한다
- 결함 타입을 기록해 다음 글에 반영한다
- 비평 → 수정 → 재검수를 최소 2회 돌린다
- “좋다/나쁘다”가 아니라 **문제의 종류**를 찾는다

## 참고 링크

- Self-Refine: Iterative Refinement with Self-Feedback — https://arxiv.org/abs/2303.17651
- Constitutional AI: Harmlessness from AI Feedback — https://arxiv.org/abs/2212.08073
- Reflexion: Language Agents with Verbal Reinforcement Learning — https://arxiv.org/abs/2303.11366
